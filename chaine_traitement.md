# Cha√Æne de traitement

## Extraire les textes des images
La strat√©gie consiste √† combiner deux solutions :
- R√©-oc√©riser les textes les plus fautifs et les post-corriger
- Corriger les textes d√©j√† oc√©ris√©s les moins fautifs 
L'id√©e est de pouvoir avancer sur l'annotation en TEI m√™me si tout le corpus n'est pas corrig√©.

### Cr√©er une IA capable de diviser le corpus en textes peu fautifs / textes tr√®s fautifs

Evaluer le taux d'erreur entre Gallica, OCR Tesseract, Abby et eScriptorium
- Produire ground truth (en cours)
- Entra√Æner mod√®le avec eScriptorium (en cours)
- Oc√©riser avec Abby le num√©ro concern√© (√† r√©cup√©rer)

Strat√©gie de r√©oc√©risation :
- Tout r√©oc√©riser avec Tesseract ou eScriptorium
- Mesurer le taux d'erreur par page et non par num√©ro
- D√©cider d'un niveau o√π la r√©oc√©risation est n√©cessaire (certaines pages en ont besoin plus que d'autres)
- Cr√©er SVM
- R√©oc√©riser avec Abby Reader

**Etapes**

*Evaluer le taux d'erreur entre Gallica, OCR Tesseract, Abby et eScriptorium*
1. Produire ground truth (en cours)
2. Entra√Æner mod√®le avec eScriptorium (en cours)
3. Oc√©riser avec Abby le num√©ro concern√© (√† r√©cup√©rer)
4. Mesurer le taux d'erreur par page et non par num√©ro (car le r√©sultat diff√©re beaucoup entre les pages au sein d'un mÍme numÈro)

*Strat√©gie de r√©oc√©risation*
1. D√©cider d'un niveau o√π la r√©oc√©risation est n√©cessaire (quel est le pourcentage d'erreur trop √©lev√© ?)
2. Faut-il tout r√©oc√©riser avec Tesseract ou eScriptorium ? A d√©cider en fonction des r√©sultats de l'√©valuation de l'accuracy de l'OCR de Gallica.
3. Cr√©er IA (SVM )
4. Pr√©traitement de l'image (cf. ci-dessous "Am√©liorer les images d'origine")
5. R√©oc√©riser avec Abby Reader

### Am√©liorer les images d'origine
- Eliminer la courbure de la page. Une id√©e int√©ressante consiste √† r√©aliser un traitement OCR s√©quentiel de chaque tron√ßon de baseline, chacun redress√© ind√©pendamment puis reconnu. La ligne de texte √©tant ensuite ¬´ recompos√©e ¬ª (facile, puisque tout appartient √† la m√™me baseline √† la base). C‚Äôest librement inspir√© de ce qui est d√©crit ici : [https://arxiv.org/pdf/2102.08742.pdf](https://arxiv.org/pdf/2102.08742.pdf)

### Post-corriger les textes
Plusieurs approches :
- Utiliser un dictionnaire : pyspellchecker (cr√©er un dictionnaire adapat√©) ou solution d'Edwin)
- Utiliser une solution endog√®ne (cf. script d'Eric en perl qui permet de conserver la trace de la correction via une balise TEI <corr>)
Bibliographie √† utiliser :
Nguyen, Thi-Tuyet-Hai, Adam Jatowt, MIickael Coustaty, et Antoine Doucet. 2021. ¬´ Survey of Post-OCR Processing Approaches ¬ª. _ACM Computing Surveys_ 1, 1 (March 2020) (mars): 36. [https://doi.org/10.5281/zenodo.4640070](https://doi.org/10.5281/zenodo.4640070).
Rigaud, Christophe, Antoine Doucet, Micka√´l Coustaty, et Jean-Philippe Moreux. 2019. ¬´ ICDAR 2019 Competition on Post-OCR Text Correction ¬ª. In _15th International Conference on Document Analysis and Recognition_, 1588‚Äë93. Sydney, Australia. [https://hal.archives-ouvertes.fr/hal-02304334](https://hal.archives-ouvertes.fr/hal-02304334).

## Annoter automatiquement les textes en TEI
- Cr√©er un sch√©ma XML appropri√© et un ODD document√©
- Utiliser les scripts Python d√©velopp√©s dans le cadre d'eScriptorium (cf. gitlab)
- TEI process (d√©velopp√© par Eric) (cf. gitlab). Permet notamment

## Reconnaissance des entit√©s nomm√©es
- Cha√Æne de traitement FRMG pour le fran√ßais 
- Mod√®le de langue pour le fran√ßais : CamemBERT (√† privil√©gier car plus √† jour)

## Topic Modeling
Eric proposait de r√©aliser √©galement le topic modeling sur les bigrammes.

Quelle est la granularit√© th√©matique d√©sir√©e ?
- Th√©matique : plus g√©n√©rique ? (International, √©conomie...)
- Th√©matique plus pr√©cise ? (Par exemple : le canal de Panama...)

Identifier les grandes th√©matiques et mettre les documents dans chaque cat√©gorie et entra√Æner un classifieur multiclasse. Le classifieur peut s'appuyer sur tout le contenu du texte.
L'id√©e est d'associer √† chaque fragment √† son topic et entrainer plusieurs classifieur qui vont associer un degr√© de probabilit√© avec un nouveau texte.
 
On pourrait annoter chaque d√©bat avec un th√®me large et ajouter une th√©matique plus pr√©cise, par exemple au niveau des titres.

On peut envisager d'aller plus loin en annotant les mots appartenant √† un topic en utilisant le m√©canisme des id (<w xml-id="345">Tonkin</w>) en utilisant un <span>. On pourrait ainsi avoir plusieurs topics sur un paragraphe. Une liste d'√©tiquette serait affich√©e et tu mets en √©vidence les mots apr√®s avoir cliqu√© sur l'√©tiquette.

Il faut peut-√™tre travailler avec les embeddings et r√©cup√©rer les embeddings qui sont des embeddings du topic (√† √©claircir..)
